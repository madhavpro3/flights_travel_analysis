{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4242016,"sourceType":"datasetVersion","datasetId":2500051}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-10-18T11:13:02.828918Z","iopub.execute_input":"2024-10-18T11:13:02.830026Z","iopub.status.idle":"2024-10-18T11:13:03.224677Z","shell.execute_reply.started":"2024-10-18T11:13:02.829977Z","shell.execute_reply":"2024-10-18T11:13:03.223638Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"airports=pd.read_csv('/kaggle/input/datasets-for-pyspark-project/airports.csv')\nflights=pd.read_csv('/kaggle/input/datasets-for-pyspark-project/flights_small.csv')\nplanes=pd.read_csv('/kaggle/input/datasets-for-pyspark-project/planes.csv')\n\nairports.to_csv('airports.csv')\nflights.to_csv('flights.csv')\nplanes.to_csv('planes.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T11:15:36.239170Z","iopub.execute_input":"2024-10-18T11:15:36.240142Z","iopub.status.idle":"2024-10-18T11:15:36.396262Z","shell.execute_reply.started":"2024-10-18T11:15:36.240083Z","shell.execute_reply":"2024-10-18T11:15:36.395138Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"!pip install pyspark","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T11:13:10.505781Z","iopub.execute_input":"2024-10-18T11:13:10.506200Z","iopub.status.idle":"2024-10-18T11:14:01.226150Z","shell.execute_reply.started":"2024-10-18T11:13:10.506162Z","shell.execute_reply":"2024-10-18T11:14:01.224912Z"}},"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840629 sha256=f4b51058c17b18c86afad12114f22b4c3d889de5c9f4ee2c749d8fc1c95936e0\n  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.5.3\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from pyspark.sql import SparkSession\n\nsparksess=SparkSession.builder.getOrCreate()\nprint(sparksess)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T11:13:03.232805Z","iopub.execute_input":"2024-10-18T11:13:03.233642Z","iopub.status.idle":"2024-10-18T11:13:03.287277Z","shell.execute_reply.started":"2024-10-18T11:13:03.233592Z","shell.execute_reply":"2024-10-18T11:13:03.285430Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      3\u001b[0m sparksess\u001b[38;5;241m=\u001b[39mSparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(sparksess)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"],"ename":"ModuleNotFoundError","evalue":"No module named 'pyspark'","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"print(sparksess.catalog.listTables())\n\n# airports=pd.read_csv('/kaggle/input/datasets-for-pyspark-project/airports.csv')\n# flights=pd.read_csv('/kaggle/input/datasets-for-pyspark-project/flights_small.csv')\n# planes=pd.read_csv('/kaggle/input/datasets-for-pyspark-project/planes.csv')\n\n# sp_airports=sparksess.createDataFrame(airports)\n# sp_flights=sparksess.createDataFrame(flights)\n# sp_planes=sparksess.createDataFrame(planes)\n\n# sp_airports.createOrReplaceTempView('airports')\n# sp_flights.createOrReplaceTempView('flights')\n# sp_planes.createOrReplaceTempView('planes')\n\nsp_airports=sparksess.read.csv('/kaggle/input/datasets-for-pyspark-project/airports.csv',header=True)\nsp_flights=sparksess.read.csv('/kaggle/input/datasets-for-pyspark-project/flights_small.csv',header=True)\nsp_planes=sparksess.read.csv('/kaggle/input/datasets-for-pyspark-project/planes.csv',header=True)\n\nprint(sparksess.catalog.listTables())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T11:13:03.288608Z","iopub.status.idle":"2024-10-18T11:13:03.289202Z","shell.execute_reply.started":"2024-10-18T11:13:03.288912Z","shell.execute_reply":"2024-10-18T11:13:03.288943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q1=sparksess.sql(\"Select * from airports\")\nq1.show()\n# q1.toPandas() to convert the data into pandas dataframe","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T11:13:03.290902Z","iopub.status.idle":"2024-10-18T11:13:03.291369Z","shell.execute_reply.started":"2024-10-18T11:13:03.291177Z","shell.execute_reply":"2024-10-18T11:13:03.291198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q2=sparksess.sql(\"Select * from flights limit 5\")\nq2.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T11:13:03.292563Z","iopub.status.idle":"2024-10-18T11:13:03.292986Z","shell.execute_reply.started":"2024-10-18T11:13:03.292759Z","shell.execute_reply":"2024-10-18T11:13:03.292782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q3=sparksess.sql(\"select * from planes limit 5\")\nq3.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T11:13:03.294576Z","iopub.status.idle":"2024-10-18T11:13:03.295030Z","shell.execute_reply.started":"2024-10-18T11:13:03.294769Z","shell.execute_reply":"2024-10-18T11:13:03.294788Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Questions to explore\n* How many flights used a particular airport by year?\n* What is the distribution of flight types?\n* Which manufacturer flights used a particular airport by year?","metadata":{}},{"cell_type":"code","source":"sparksess.sql(\"Select manufacturer,count(manufacturer) as num_planes from planes\").show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T11:12:54.938584Z","iopub.execute_input":"2024-10-18T11:12:54.939059Z","iopub.status.idle":"2024-10-18T11:12:55.248980Z","shell.execute_reply.started":"2024-10-18T11:12:54.939005Z","shell.execute_reply":"2024-10-18T11:12:55.247175Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msparksess\u001b[49m\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelect manufacturer,count(manufacturer) as num_planes from planes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow()\n","\u001b[0;31mNameError\u001b[0m: name 'sparksess' is not defined"],"ename":"NameError","evalue":"name 'sparksess' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}